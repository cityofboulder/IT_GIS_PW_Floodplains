{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming SFHAs\n",
    "\n",
    "This notebook experiments with transforming data from REST API queries in-place, either in pandas dataframes or python dicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting corrected LOMRs and all flood delineations inside those LOMRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.features import Feature, FeatureSet, FeatureLayer, FeatureLayerCollection, SpatialDataFrame\n",
    "from arcgis.geometry import Geometry, Point, filters, union, buffer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature services\n",
    "city_lims_url = \"https://maps.bouldercolorado.gov/arcgis/rest/services/plan/CityLimits/MapServer/0\"\n",
    "city = FeatureLayer(city_lims_url)\n",
    "\n",
    "nfhl_url = \"https://hazards.fema.gov/gis/nfhl/rest/services/public/NFHL/MapServer\"\n",
    "nfhl = FeatureLayerCollection(nfhl_url)\n",
    "lomr = nfhl.layers[1]\n",
    "sfha = nfhl.layers[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 2876 # NAD83(HARN) / Colorado North (ftUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry filter object\n",
    "anon_gis = GIS()\n",
    "city_lims = city.query(out_sr=sr)\n",
    "city_geoms = [poly.geometry for poly in city_lims.features]\n",
    "city_union = union(spatial_ref=sr, geometries=city_geoms, gis=anon_gis)\n",
    "geom_filter = filters.intersects(city_union, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "date_str = '2018-08-16'\n",
    "clause = f\"STATUS = 'Effective' AND EFF_DATE >= '{date_str}'\"\n",
    "boulder_lomrs = lomr.query(where=clause,\n",
    "                           geometry_filter=geom_filter,\n",
    "                           out_sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop LOMR polygons that have duplicate Case Numbers and Geometries.\n",
    "temp = boulder_lomrs.sdf\n",
    "temp['GEOM_STR'] = str(temp['SHAPE'])\n",
    "temp.drop_duplicates(subset=['CASE_NO', 'GEOM_STR'], inplace=True)\n",
    "temp.sort_values(by='EFF_DATE', inplace=True, ascending=False)\n",
    "boulder_lomrs = FeatureSet.from_dataframe(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query BoCo flood areas\n",
    "flood_areas = sfha.query(where=\"DFIRM_ID = '08013C'\",\n",
    "                         out_fields=['FLD_AR_ID', 'STUDY_TYP', 'FLD_ZONE', 'ZONE_SUBTY', 'SFHA_TF', 'STATIC_BFE', 'DEPTH'],\n",
    "                         out_sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy BoCo flood areas and empty the df\n",
    "flood_sdf = flood_areas.sdf\n",
    "flood = flood_sdf.copy()\n",
    "flood.drop(list(range(len(flood))),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through LOMRs and flood areas to find polys inside LOMRs\n",
    "for l in boulder_lomrs.features:\n",
    "    g = Geometry(l.geometry)\n",
    "    \n",
    "    # buffer LOMR geom by one foot to avoid topological\n",
    "    # errors where polys share an edge\n",
    "    buf = g.buffer(1)\n",
    "\n",
    "    for row in flood_areas.features:\n",
    "        area_id = row.attributes['FLD_AR_ID']\n",
    "        f = Geometry(row.geometry)\n",
    "        if buf.contains(f):\n",
    "            flood = flood.append(flood_sdf[flood_sdf['FLD_AR_ID'] == area_id], ignore_index=True)\n",
    "\n",
    "# drop any rows that represent duplicate flood areas\n",
    "flood.drop_duplicates(subset=['FLD_AR_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the SFHAs\n",
    "\n",
    "### Criteria:\n",
    "- FLOODPLAIN\n",
    "  - 500-Year = \"FLD_ZONE = 'X' AND ZONE_SUBTY IN ('0.2 PCT ANNUAL CHANCE FLOOD HAZARD', 'LEVEE')\"\n",
    "  - 100-Year = \"SFHA_TF = 'T'\"\n",
    "    - Conveyance Zone = \"SFHA_TF = 'T' AND 'ZONE_SUBTY' = 'FLOODWAY'\"\n",
    "- LIFECYCLE = 'Active'\n",
    "- FEMAZONE\n",
    "  - if FLD_ZONE = AO\n",
    "    - FEMAZONE = FLD_ZONE + str(DEPTH)\n",
    "  - if FLD_ZONE = AH\n",
    "    - FEMAZONE = FLD_ZONE + str(STATIC_BFE)\n",
    "- SOURCE = 'FEMA'\n",
    "- ADOPTDATE and INEFFDATE (Spatial join of dataframes)\n",
    "  - If a polygon resides in 2+ different LOMR areas, the join creates 2+ polygons\n",
    "    - The polygon with the earlier ADOPTDATE gets an INEFFDATE equal to the next later ADOPTDATE\n",
    "    - The polygon with the latest ADOPTDATE gets a null INEFFDATE\n",
    "- DRAINAGE\n",
    "  - Use \"set-theoretic\" funcs: centroid inside city-floodplain with DRAINAGE = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ADOPT and INEFFDATEs\n",
    "def calc_ineffdate(row, date_dict):\n",
    "    fema_id = row[\"FLD_AR_ID\"]\n",
    "    adopt_date = row[\"EFF_DATE\"]\n",
    "    ineff_date = None\n",
    "    try:\n",
    "        idx = date_dict[fema_id].index(adopt_date)\n",
    "        try:\n",
    "            ineff_date = date_dict[fema_id][idx+1]\n",
    "        except IndexError:\n",
    "            # The polygon has the most recent ADOPTDATE of all the LOMRs that touch the polygon\n",
    "            pass\n",
    "    except KeyError:\n",
    "        # The polygon was not duplicated\n",
    "        pass\n",
    "    return ineff_date\n",
    "\n",
    "flood = flood.spatial.join(boulder_lomrs.sdf)\n",
    "dups = list(flood[flood.duplicated([\"FLD_AR_ID\"])][\"FLD_AR_ID\"])\n",
    "dup_dates = {fld_ar_id: sorted(list(flood[flood[\"FLD_AR_ID\"]==fld_ar_id][\"EFF_DATE\"])) for fld_ar_id in dups}\n",
    "flood[\"INEFFDATE\"] = flood.apply(calc_ineffdate, date_dict=dup_dates, axis=1)\n",
    "flood.rename(columns={\"EFF_DATE\": \"ADOPTDATE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_floodplain(row):\n",
    "    if row[\"SFHA_TF\"] == \"T\":\n",
    "        if row[\"ZONE_SUBTY\"] == 'FLOODWAY':\n",
    "            floodplain = 'Conveyance Zone'\n",
    "        else:\n",
    "            floodplain = '100-Year'\n",
    "    else:\n",
    "        if row[\"ZONE_SUBTY\"] in ('0.2 PCT ANNUAL CHANCE FLOOD HAZARD', 'AREA WITH REDUCED FLOOD RISK DUE TO LEVEE'):\n",
    "            floodplain = '500-Year'\n",
    "        else:\n",
    "            floodplain = None\n",
    "    return floodplain\n",
    "\n",
    "def calc_femazone(row):\n",
    "    if row[\"FLD_ZONE\"] == 'AO':\n",
    "        zone = 'AO' + str(round(row['DEPTH']))\n",
    "    elif row[\"FLD_ZONE\"] == 'AH':\n",
    "        zone = 'AH' + str(round(row[\"STATIC_BFE\"]))\n",
    "    else:\n",
    "        zone = row[\"FLD_ZONE\"]\n",
    "    return zone\n",
    "\n",
    "\n",
    "flood[\"FLOODPLAIN\"] = flood.apply(calc_floodplain, axis=1)\n",
    "flood[\"FEMAZONE\"] = flood.apply(calc_femazone, axis=1)\n",
    "flood.loc[flood[\"INEFFDATE\"].notnull(), \"LIFECYCLE\"] = \"Inactive\"\n",
    "flood.loc[flood[\"INEFFDATE\"].isnull(), \"LIFECYCLE\"] = \"Active\"\n",
    "flood[\"SOURCE\"] = \"FEMA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_flood_url = \"https://maps.bouldercolorado.gov/arcgis3/rest/services/util/Floodplain/MapServer/3\"\n",
    "city_flood = FeatureLayer(city_flood_url)\n",
    "sfha_compare = city_flood.query(out_fields=['DRAINAGE'], out_sr=2876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union the city drainages\n",
    "def union_drainages(row):\n",
    "    no_sr = union(geometries=row[\"SHAPE\"], spatial_ref=sr, gis=anon_gis)\n",
    "    geom = Geometry({\"rings\": no_sr.rings, \"spatialReference\": {\"wkid\": sr}})\n",
    "    return geom\n",
    "\n",
    "drainages = pd.DataFrame(sfha_compare.sdf.groupby(\"DRAINAGE\")[\"SHAPE\"].apply(list)).reset_index()\n",
    "drainages[\"SHAPE\"] = drainages.apply(union_drainages, axis=1)\n",
    "drain_fs = FeatureSet.from_dataframe(drainages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_point_in_poly(row):\n",
    "    rand = row[\"SHAPE\"].as_shapely.representative_point()\n",
    "    point = Geometry({\"x\": rand.x, \"y\": rand.y, \"spatialReference\": {\"wkid\": sr}})\n",
    "    return point\n",
    "\n",
    "def calc_drainage(row):\n",
    "    for item in drain_fs.features:\n",
    "        arcgis_point = rand_point_in_poly(row)\n",
    "        g = Geometry(item.geometry)\n",
    "        if g.contains(arcgis_point):\n",
    "            drain = item.attributes[\"DRAINAGE\"]\n",
    "            return drain\n",
    "\n",
    "# Calc drainages over\n",
    "flood[\"DRAINAGE\"] = flood.apply(calc_drainage, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all non-floodplain areas and non-essential columns\n",
    "flood = flood[flood[\"ZONE_SUBTY\"] != \"AREA OF MINIMAL FLOOD HAZARD\"]\n",
    "flood = flood[[\"FLOODPLAIN\", \"DRAINAGE\", \"FEMAZONE\", \"LIFECYCLE\", \"ADOPTDATE\", \"INEFFDATE\", \"SOURCE\", \"SHAPE\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1597189567475"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}